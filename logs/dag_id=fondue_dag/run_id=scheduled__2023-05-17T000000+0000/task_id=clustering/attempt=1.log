<<<<<<< HEAD
[2023-05-18T06:41:19.624+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-17T00:00:00+00:00 [queued]>
[2023-05-18T06:41:19.647+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-17T00:00:00+00:00 [queued]>
[2023-05-18T06:41:19.648+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 2
[2023-05-18T06:41:19.690+0000] {taskinstance.py:1350} INFO - Executing <Task(PythonOperator): clustering> on 2023-05-17 00:00:00+00:00
[2023-05-18T06:41:19.701+0000] {standard_task_runner.py:57} INFO - Started process 1385 to run task
[2023-05-18T06:41:19.705+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'fondue_dag', 'clustering', 'scheduled__2023-05-17T00:00:00+00:00', '--job-id', '36', '--raw', '--subdir', 'DAGS_FOLDER/fondue_dag.py', '--cfg-path', '/tmp/tmpc967_qwv']
[2023-05-18T06:41:19.708+0000] {standard_task_runner.py:85} INFO - Job 36: Subtask clustering
[2023-05-18T06:41:19.810+0000] {task_command.py:410} INFO - Running <TaskInstance: fondue_dag.clustering scheduled__2023-05-17T00:00:00+00:00 [running]> on host 714a0c7ad307
[2023-05-18T06:41:20.006+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='Bhuribhat@gmail.com' AIRFLOW_CTX_DAG_OWNER='pras' AIRFLOW_CTX_DAG_ID='fondue_dag' AIRFLOW_CTX_TASK_ID='clustering' AIRFLOW_CTX_EXECUTION_DATE='2023-05-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-05-17T00:00:00+00:00'
[2023-05-18T06:41:46.343+0000] {logging_mixin.py:149} WARNING - 2023/05/18 06:41:46 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
=======
[2023-05-18T04:22:23.784+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-17T00:00:00+00:00 [queued]>
[2023-05-18T04:22:23.844+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-17T00:00:00+00:00 [queued]>
[2023-05-18T04:22:23.848+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 2
[2023-05-18T04:22:23.914+0000] {taskinstance.py:1350} INFO - Executing <Task(PythonOperator): clustering> on 2023-05-17 00:00:00+00:00
[2023-05-18T04:22:23.923+0000] {standard_task_runner.py:57} INFO - Started process 611 to run task
[2023-05-18T04:22:23.938+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'fondue_dag', 'clustering', 'scheduled__2023-05-17T00:00:00+00:00', '--job-id', '37', '--raw', '--subdir', 'DAGS_FOLDER/fondue_dag.py', '--cfg-path', '/tmp/tmpra_6x92k']
[2023-05-18T04:22:23.945+0000] {standard_task_runner.py:85} INFO - Job 37: Subtask clustering
[2023-05-18T04:22:24.185+0000] {task_command.py:410} INFO - Running <TaskInstance: fondue_dag.clustering scheduled__2023-05-17T00:00:00+00:00 [running]> on host b36de7cfc389
[2023-05-18T04:22:24.317+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='Bhuribhat@gmail.com' AIRFLOW_CTX_DAG_OWNER='pras' AIRFLOW_CTX_DAG_ID='fondue_dag' AIRFLOW_CTX_TASK_ID='clustering' AIRFLOW_CTX_EXECUTION_DATE='2023-05-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-05-17T00:00:00+00:00'
[2023-05-18T04:23:08.814+0000] {logging_mixin.py:149} WARNING - 2023/05/18 04:23:08 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
>>>>>>> 8e4a41b368593e9ce283ae02afd6c27252f67370
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh()

All git commands will error until this is rectified.

This initial warning can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|none|n|0: for no warning or exception
    - warn|w|warning|1: for a printed warning
    - error|e|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet
<<<<<<< HEAD
[2023-05-18T06:41:46.506+0000] {taskinstance.py:1847} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 181, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 198, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/utils/clustering.py", line 46, in kmean_cluster
    with mlflow.start_run() as run:
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/tracking/fluent.py", line 277, in start_run
    ).format(_active_run_stack[0].info.run_id)
Exception: Run with UUID 5cc22fb2663f40f3b7b696622a5c1a5e is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
[2023-05-18T06:41:46.533+0000] {taskinstance.py:1373} INFO - Marking task as UP_FOR_RETRY. dag_id=fondue_dag, task_id=clustering, execution_date=20230517T000000, start_date=20230518T064119, end_date=20230518T064146
[2023-05-18T06:41:46.569+0000] {configuration.py:675} WARNING - section/key [smtp/smtp_user] not found in config
[2023-05-18T06:41:46.570+0000] {email.py:268} INFO - Email alerting: attempt 1
[2023-05-18T06:41:46.583+0000] {configuration.py:675} WARNING - section/key [smtp/smtp_user] not found in config
[2023-05-18T06:41:46.585+0000] {email.py:268} INFO - Email alerting: attempt 1
[2023-05-18T06:41:46.586+0000] {taskinstance.py:1912} ERROR - Failed to send email to: ['Bhuribhat@gmail.com']
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1430, in _run_raw_task
    self._execute_task_with_callbacks(context, test_mode)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1581, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1651, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 181, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 198, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/utils/clustering.py", line 46, in kmean_cluster
    with mlflow.start_run() as run:
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/tracking/fluent.py", line 277, in start_run
    ).format(_active_run_stack[0].info.run_id)
Exception: Run with UUID 5cc22fb2663f40f3b7b696622a5c1a5e is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2318, in email_alert
    send_email(task.email, subject, html_content)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 91, in send_email
    **kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 152, in send_email_smtp
    send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 270, in send_mime_email
    smtp_conn = _get_smtp_connection(smtp_host, smtp_port, smtp_timeout, smtp_ssl)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 317, in _get_smtp_connection
    else smtplib.SMTP(host=host, port=port, timeout=timeout)
  File "/usr/local/lib/python3.7/smtplib.py", line 251, in __init__
    (code, msg) = self.connect(host, port)
  File "/usr/local/lib/python3.7/smtplib.py", line 336, in connect
    self.sock = self._get_socket(host, port, self.timeout)
  File "/usr/local/lib/python3.7/smtplib.py", line 307, in _get_socket
    self.source_address)
  File "/usr/local/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/usr/local/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 99] Cannot assign requested address

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1910, in handle_failure
    self.email_alert(error, task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2320, in email_alert
    send_email(task.email, subject, html_content_err)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 91, in send_email
    **kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 152, in send_email_smtp
    send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 270, in send_mime_email
    smtp_conn = _get_smtp_connection(smtp_host, smtp_port, smtp_timeout, smtp_ssl)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 317, in _get_smtp_connection
    else smtplib.SMTP(host=host, port=port, timeout=timeout)
  File "/usr/local/lib/python3.7/smtplib.py", line 251, in __init__
    (code, msg) = self.connect(host, port)
  File "/usr/local/lib/python3.7/smtplib.py", line 336, in connect
    self.sock = self._get_socket(host, port, self.timeout)
  File "/usr/local/lib/python3.7/smtplib.py", line 307, in _get_socket
    self.source_address)
  File "/usr/local/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/usr/local/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 99] Cannot assign requested address
[2023-05-18T06:41:46.614+0000] {standard_task_runner.py:109} ERROR - Failed to execute job 36 for task clustering (Run with UUID 5cc22fb2663f40f3b7b696622a5c1a5e is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True; 1385)
[2023-05-18T06:41:46.672+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 1
[2023-05-18T06:41:46.713+0000] {taskinstance.py:2674} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-18T06:53:12.308+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-17T00:00:00+00:00 [queued]>
[2023-05-18T06:53:12.329+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-17T00:00:00+00:00 [queued]>
[2023-05-18T06:53:12.330+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 2
[2023-05-18T06:53:12.355+0000] {taskinstance.py:1350} INFO - Executing <Task(PythonOperator): clustering> on 2023-05-17 00:00:00+00:00
[2023-05-18T06:53:12.364+0000] {standard_task_runner.py:57} INFO - Started process 805 to run task
[2023-05-18T06:53:12.368+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'fondue_dag', 'clustering', 'scheduled__2023-05-17T00:00:00+00:00', '--job-id', '18', '--raw', '--subdir', 'DAGS_FOLDER/fondue_dag.py', '--cfg-path', '/tmp/tmpcgryav5r']
[2023-05-18T06:53:12.371+0000] {standard_task_runner.py:85} INFO - Job 18: Subtask clustering
[2023-05-18T06:53:12.442+0000] {task_command.py:410} INFO - Running <TaskInstance: fondue_dag.clustering scheduled__2023-05-17T00:00:00+00:00 [running]> on host 26547302378e
[2023-05-18T06:53:12.618+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='Bhuribhat@gmail.com' AIRFLOW_CTX_DAG_OWNER='pras' AIRFLOW_CTX_DAG_ID='fondue_dag' AIRFLOW_CTX_TASK_ID='clustering' AIRFLOW_CTX_EXECUTION_DATE='2023-05-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-05-17T00:00:00+00:00'
[2023-05-18T06:53:14.937+0000] {logging_mixin.py:149} WARNING - 2023/05/18 06:53:14 INFO mlflow.tracking.fluent: Experiment with name 'fondue' does not exist. Creating a new experiment.
[2023-05-18T06:53:15.283+0000] {logging_mixin.py:149} WARNING - 2023/05/18 06:53:15 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh()

All git commands will error until this is rectified.

This initial warning can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|none|n|0: for no warning or exception
    - warn|w|warning|1: for a printed warning
    - error|e|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet
[2023-05-18T06:53:23.616+0000] {python.py:183} INFO - Done. Returned value was: None
[2023-05-18T06:53:23.636+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=fondue_dag, task_id=clustering, execution_date=20230517T000000, start_date=20230518T065312, end_date=20230518T065323
[2023-05-18T06:53:23.815+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2023-05-18T06:53:23.857+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
=======
[2023-05-18T04:23:16.090+0000] {python.py:183} INFO - Done. Returned value was: None
[2023-05-18T04:23:16.111+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=fondue_dag, task_id=clustering, execution_date=20230517T000000, start_date=20230518T042223, end_date=20230518T042316
[2023-05-18T04:23:16.188+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2023-05-18T04:23:16.244+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
>>>>>>> 8e4a41b368593e9ce283ae02afd6c27252f67370
[2023-05-18T07:20:40.269+0000] {logging_mixin.py:149} INFO - Changing /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-17T00:00:00+00:00/task_id=clustering permission to 509
[2023-05-18T07:20:40.271+0000] {logging_mixin.py:149} INFO - Failed to change /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-17T00:00:00+00:00/task_id=clustering permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-17T00:00:00+00:00/task_id=clustering'
[2023-05-18T07:20:40.371+0000] {logging_mixin.py:149} INFO - Changing /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-17T00:00:00+00:00/task_id=clustering permission to 509
[2023-05-18T07:20:40.373+0000] {logging_mixin.py:149} INFO - Failed to change /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-17T00:00:00+00:00/task_id=clustering permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-17T00:00:00+00:00/task_id=clustering'
[2023-05-18T07:20:40.449+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-17T00:00:00+00:00 [queued]>
[2023-05-18T07:20:40.538+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-17T00:00:00+00:00 [queued]>
[2023-05-18T07:20:40.539+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 2
[2023-05-18T07:20:40.604+0000] {taskinstance.py:1350} INFO - Executing <Task(PythonOperator): clustering> on 2023-05-17 00:00:00+00:00
[2023-05-18T07:20:40.622+0000] {standard_task_runner.py:57} INFO - Started process 1202 to run task
[2023-05-18T07:20:40.631+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'fondue_dag', 'clustering', 'scheduled__2023-05-17T00:00:00+00:00', '--job-id', '32', '--raw', '--subdir', 'DAGS_FOLDER/fondue_dag.py', '--cfg-path', '/tmp/tmp2rzssz2c']
[2023-05-18T07:20:40.643+0000] {standard_task_runner.py:85} INFO - Job 32: Subtask clustering
[2023-05-18T07:20:40.760+0000] {logging_mixin.py:149} INFO - Changing /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-17T00:00:00+00:00/task_id=clustering permission to 509
[2023-05-18T07:20:40.764+0000] {logging_mixin.py:149} INFO - Failed to change /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-17T00:00:00+00:00/task_id=clustering permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-17T00:00:00+00:00/task_id=clustering'
[2023-05-18T07:20:40.778+0000] {task_command.py:410} INFO - Running <TaskInstance: fondue_dag.clustering scheduled__2023-05-17T00:00:00+00:00 [running]> on host 0a50b96f7e57
[2023-05-18T07:20:41.060+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='Bhuribhat@gmail.com' AIRFLOW_CTX_DAG_OWNER='pras' AIRFLOW_CTX_DAG_ID='fondue_dag' AIRFLOW_CTX_TASK_ID='clustering' AIRFLOW_CTX_EXECUTION_DATE='2023-05-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-05-17T00:00:00+00:00'
[2023-05-18T07:20:53.327+0000] {file_store.py:280} WARNING - Malformed experiment 'models'. Detailed error Yaml file '/opt/***/mlruns/models/meta.yaml' does not exist.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 271, in list_experiments
    experiment = self._get_experiment(exp_id, view_type)
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 405, in _get_experiment
    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 1109, in _read_yaml
    return _read_helper(root, file_name, attempts_remaining=retries)
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 1102, in _read_helper
    result = read_yaml(root, file_name)
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/utils/file_utils.py", line 183, in read_yaml
    raise MissingConfigException("Yaml file '%s' does not exist." % file_path)
mlflow.exceptions.MissingConfigException: Yaml file '/opt/***/mlruns/models/meta.yaml' does not exist.
[2023-05-18T07:20:53.448+0000] {logging_mixin.py:149} WARNING - 2023/05/18 07:20:53 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh()

All git commands will error until this is rectified.

This initial warning can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|none|n|0: for no warning or exception
    - warn|w|warning|1: for a printed warning
    - error|e|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet
[2023-05-18T07:21:05.994+0000] {python.py:183} INFO - Done. Returned value was: None
[2023-05-18T07:21:06.043+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=fondue_dag, task_id=clustering, execution_date=20230517T000000, start_date=20230518T072040, end_date=20230518T072106
[2023-05-18T07:21:06.429+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2023-05-18T07:21:06.517+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-05-18T07:38:34.022+0000] {logging_mixin.py:149} INFO - Changing /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-17T00:00:00+00:00/task_id=clustering permission to 509
[2023-05-18T07:38:34.023+0000] {logging_mixin.py:149} INFO - Failed to change /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-17T00:00:00+00:00/task_id=clustering permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-17T00:00:00+00:00/task_id=clustering'
[2023-05-18T07:38:34.106+0000] {logging_mixin.py:149} INFO - Changing /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-17T00:00:00+00:00/task_id=clustering permission to 509
[2023-05-18T07:38:34.107+0000] {logging_mixin.py:149} INFO - Failed to change /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-17T00:00:00+00:00/task_id=clustering permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-17T00:00:00+00:00/task_id=clustering'
[2023-05-18T07:38:34.160+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-17T00:00:00+00:00 [queued]>
[2023-05-18T07:38:34.202+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-17T00:00:00+00:00 [queued]>
[2023-05-18T07:38:34.203+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 2
[2023-05-18T07:38:34.251+0000] {taskinstance.py:1350} INFO - Executing <Task(PythonOperator): clustering> on 2023-05-17 00:00:00+00:00
[2023-05-18T07:38:34.268+0000] {standard_task_runner.py:57} INFO - Started process 1096 to run task
[2023-05-18T07:38:34.283+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'fondue_dag', 'clustering', 'scheduled__2023-05-17T00:00:00+00:00', '--job-id', '36', '--raw', '--subdir', 'DAGS_FOLDER/fondue_dag.py', '--cfg-path', '/tmp/tmp_llhfhwn']
[2023-05-18T07:38:34.289+0000] {standard_task_runner.py:85} INFO - Job 36: Subtask clustering
[2023-05-18T07:38:34.371+0000] {logging_mixin.py:149} INFO - Changing /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-17T00:00:00+00:00/task_id=clustering permission to 509
[2023-05-18T07:38:34.375+0000] {logging_mixin.py:149} INFO - Failed to change /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-17T00:00:00+00:00/task_id=clustering permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-17T00:00:00+00:00/task_id=clustering'
[2023-05-18T07:38:34.388+0000] {task_command.py:410} INFO - Running <TaskInstance: fondue_dag.clustering scheduled__2023-05-17T00:00:00+00:00 [running]> on host 4fe746fadf66
[2023-05-18T07:38:34.582+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='Bhuribhat@gmail.com' AIRFLOW_CTX_DAG_OWNER='pras' AIRFLOW_CTX_DAG_ID='fondue_dag' AIRFLOW_CTX_TASK_ID='clustering' AIRFLOW_CTX_EXECUTION_DATE='2023-05-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-05-17T00:00:00+00:00'
[2023-05-18T07:38:57.988+0000] {file_store.py:280} WARNING - Malformed experiment 'models'. Detailed error Yaml file '/opt/***/mlruns/models/meta.yaml' does not exist.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 271, in list_experiments
    experiment = self._get_experiment(exp_id, view_type)
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 405, in _get_experiment
    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 1109, in _read_yaml
    return _read_helper(root, file_name, attempts_remaining=retries)
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 1102, in _read_helper
    result = read_yaml(root, file_name)
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/utils/file_utils.py", line 183, in read_yaml
    raise MissingConfigException("Yaml file '%s' does not exist." % file_path)
mlflow.exceptions.MissingConfigException: Yaml file '/opt/***/mlruns/models/meta.yaml' does not exist.
[2023-05-18T07:38:58.093+0000] {logging_mixin.py:149} WARNING - 2023/05/18 07:38:58 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh()

All git commands will error until this is rectified.

This initial warning can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|none|n|0: for no warning or exception
    - warn|w|warning|1: for a printed warning
    - error|e|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet
[2023-05-18T07:39:07.114+0000] {python.py:183} INFO - Done. Returned value was: None
[2023-05-18T07:39:07.132+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=fondue_dag, task_id=clustering, execution_date=20230517T000000, start_date=20230518T073834, end_date=20230518T073907
[2023-05-18T07:39:07.206+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2023-05-18T07:39:07.244+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
