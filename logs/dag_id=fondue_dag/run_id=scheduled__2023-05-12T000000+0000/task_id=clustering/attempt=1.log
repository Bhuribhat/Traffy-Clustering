[2023-05-17T16:46:25.716+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [queued]>
[2023-05-17T16:46:25.734+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [queued]>
[2023-05-17T16:46:25.735+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 2
[2023-05-17T16:46:25.763+0000] {taskinstance.py:1350} INFO - Executing <Task(PythonOperator): clustering> on 2023-05-12 00:00:00+00:00
[2023-05-17T16:46:25.775+0000] {standard_task_runner.py:57} INFO - Started process 1715 to run task
[2023-05-17T16:46:25.779+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'fondue_dag', 'clustering', 'scheduled__2023-05-12T00:00:00+00:00', '--job-id', '33', '--raw', '--subdir', 'DAGS_FOLDER/fondue_dag.py', '--cfg-path', '/tmp/tmp6tfcx2dt']
[2023-05-17T16:46:25.782+0000] {standard_task_runner.py:85} INFO - Job 33: Subtask clustering
[2023-05-17T16:46:25.855+0000] {task_command.py:410} INFO - Running <TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [running]> on host 8cf8fb9e28f7
[2023-05-17T16:46:26.007+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='Bhuribhat@gmail.com' AIRFLOW_CTX_DAG_OWNER='pras' AIRFLOW_CTX_DAG_ID='fondue_dag' AIRFLOW_CTX_TASK_ID='clustering' AIRFLOW_CTX_EXECUTION_DATE='2023-05-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-05-12T00:00:00+00:00'
[2023-05-17T16:46:42.430+0000] {logging_mixin.py:149} WARNING - 2023/05/17 16:46:42 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh()

All git commands will error until this is rectified.

This initial warning can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|none|n|0: for no warning or exception
    - warn|w|warning|1: for a printed warning
    - error|e|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet
[2023-05-17T16:46:47.652+0000] {python.py:183} INFO - Done. Returned value was: None
[2023-05-17T16:46:47.668+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=fondue_dag, task_id=clustering, execution_date=20230512T000000, start_date=20230517T164625, end_date=20230517T164647
[2023-05-17T16:46:47.714+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2023-05-17T16:46:47.746+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
<<<<<<< HEAD
[2023-05-17T17:55:05.792+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [queued]>
[2023-05-17T17:55:05.812+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [queued]>
[2023-05-17T17:55:05.813+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 2
[2023-05-17T17:55:05.839+0000] {taskinstance.py:1350} INFO - Executing <Task(PythonOperator): clustering> on 2023-05-12 00:00:00+00:00
[2023-05-17T17:55:05.848+0000] {standard_task_runner.py:57} INFO - Started process 864 to run task
[2023-05-17T17:55:05.851+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'fondue_dag', 'clustering', 'scheduled__2023-05-12T00:00:00+00:00', '--job-id', '33', '--raw', '--subdir', 'DAGS_FOLDER/fondue_dag.py', '--cfg-path', '/tmp/tmpayk2egdr']
[2023-05-17T17:55:05.853+0000] {standard_task_runner.py:85} INFO - Job 33: Subtask clustering
[2023-05-17T17:55:05.923+0000] {task_command.py:410} INFO - Running <TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [running]> on host a37c7bc3731c
[2023-05-17T17:55:06.092+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='Bhuribhat@gmail.com' AIRFLOW_CTX_DAG_OWNER='pras' AIRFLOW_CTX_DAG_ID='fondue_dag' AIRFLOW_CTX_TASK_ID='clustering' AIRFLOW_CTX_EXECUTION_DATE='2023-05-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-05-12T00:00:00+00:00'
[2023-05-17T17:55:28.297+0000] {logging_mixin.py:149} WARNING - 2023/05/17 17:55:28 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
=======
[2023-05-18T04:22:23.719+0000] {logging_mixin.py:149} INFO - Changing /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering permission to 509
[2023-05-18T04:22:23.720+0000] {logging_mixin.py:149} INFO - Failed to change /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering'
[2023-05-18T04:22:23.793+0000] {logging_mixin.py:149} INFO - Changing /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering permission to 509
[2023-05-18T04:22:23.794+0000] {logging_mixin.py:149} INFO - Failed to change /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering'
[2023-05-18T04:22:23.833+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [queued]>
[2023-05-18T04:22:23.874+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [queued]>
[2023-05-18T04:22:23.878+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 2
[2023-05-18T04:22:23.945+0000] {taskinstance.py:1350} INFO - Executing <Task(PythonOperator): clustering> on 2023-05-12 00:00:00+00:00
[2023-05-18T04:22:23.952+0000] {standard_task_runner.py:57} INFO - Started process 612 to run task
[2023-05-18T04:22:23.955+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'fondue_dag', 'clustering', 'scheduled__2023-05-12T00:00:00+00:00', '--job-id', '38', '--raw', '--subdir', 'DAGS_FOLDER/fondue_dag.py', '--cfg-path', '/tmp/tmp348xhiej']
[2023-05-18T04:22:23.956+0000] {standard_task_runner.py:85} INFO - Job 38: Subtask clustering
[2023-05-18T04:22:24.084+0000] {logging_mixin.py:149} INFO - Changing /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering permission to 509
[2023-05-18T04:22:24.093+0000] {logging_mixin.py:149} INFO - Failed to change /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering'
[2023-05-18T04:22:24.125+0000] {task_command.py:410} INFO - Running <TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [running]> on host b36de7cfc389
[2023-05-18T04:22:24.288+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='Bhuribhat@gmail.com' AIRFLOW_CTX_DAG_OWNER='pras' AIRFLOW_CTX_DAG_ID='fondue_dag' AIRFLOW_CTX_TASK_ID='clustering' AIRFLOW_CTX_EXECUTION_DATE='2023-05-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-05-12T00:00:00+00:00'
[2023-05-18T04:23:08.798+0000] {logging_mixin.py:149} WARNING - 2023/05/18 04:23:08 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
>>>>>>> 8e4a41b368593e9ce283ae02afd6c27252f67370
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh()

All git commands will error until this is rectified.

This initial warning can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|none|n|0: for no warning or exception
    - warn|w|warning|1: for a printed warning
    - error|e|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet
<<<<<<< HEAD
[2023-05-17T17:55:34.425+0000] {python.py:183} INFO - Done. Returned value was: None
[2023-05-17T17:55:34.444+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=fondue_dag, task_id=clustering, execution_date=20230512T000000, start_date=20230517T175505, end_date=20230517T175534
[2023-05-17T17:55:34.494+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2023-05-17T17:55:34.530+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-05-17T18:18:22.990+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [queued]>
[2023-05-17T18:18:23.017+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [queued]>
[2023-05-17T18:18:23.018+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 2
[2023-05-17T18:18:23.052+0000] {taskinstance.py:1350} INFO - Executing <Task(PythonOperator): clustering> on 2023-05-12 00:00:00+00:00
[2023-05-17T18:18:23.064+0000] {standard_task_runner.py:57} INFO - Started process 1009 to run task
[2023-05-17T18:18:23.069+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'fondue_dag', 'clustering', 'scheduled__2023-05-12T00:00:00+00:00', '--job-id', '30', '--raw', '--subdir', 'DAGS_FOLDER/fondue_dag.py', '--cfg-path', '/tmp/tmpg3eojwcx']
[2023-05-17T18:18:23.072+0000] {standard_task_runner.py:85} INFO - Job 30: Subtask clustering
[2023-05-17T18:18:23.175+0000] {task_command.py:410} INFO - Running <TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [running]> on host 3390ff13fbf6
[2023-05-17T18:18:23.359+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='Bhuribhat@gmail.com' AIRFLOW_CTX_DAG_OWNER='pras' AIRFLOW_CTX_DAG_ID='fondue_dag' AIRFLOW_CTX_TASK_ID='clustering' AIRFLOW_CTX_EXECUTION_DATE='2023-05-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-05-12T00:00:00+00:00'
[2023-05-17T18:18:36.498+0000] {logging_mixin.py:149} WARNING - 2023/05/17 18:18:36 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh()

All git commands will error until this is rectified.

This initial warning can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|none|n|0: for no warning or exception
    - warn|w|warning|1: for a printed warning
    - error|e|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet
[2023-05-17T18:18:53.321+0000] {python.py:183} INFO - Done. Returned value was: None
[2023-05-17T18:18:53.401+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=fondue_dag, task_id=clustering, execution_date=20230512T000000, start_date=20230517T181822, end_date=20230517T181853
[2023-05-17T18:18:53.798+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2023-05-17T18:18:53.830+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-05-17T18:25:55.238+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [queued]>
[2023-05-17T18:25:55.258+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [queued]>
[2023-05-17T18:25:55.259+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 2
[2023-05-17T18:25:55.295+0000] {taskinstance.py:1350} INFO - Executing <Task(PythonOperator): clustering> on 2023-05-12 00:00:00+00:00
[2023-05-17T18:25:55.341+0000] {standard_task_runner.py:57} INFO - Started process 1375 to run task
[2023-05-17T18:25:55.350+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'fondue_dag', 'clustering', 'scheduled__2023-05-12T00:00:00+00:00', '--job-id', '35', '--raw', '--subdir', 'DAGS_FOLDER/fondue_dag.py', '--cfg-path', '/tmp/tmpvx1uaed4']
[2023-05-17T18:25:55.356+0000] {standard_task_runner.py:85} INFO - Job 35: Subtask clustering
[2023-05-17T18:25:55.462+0000] {task_command.py:410} INFO - Running <TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [running]> on host 70fcd41af239
[2023-05-17T18:25:55.698+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='Bhuribhat@gmail.com' AIRFLOW_CTX_DAG_OWNER='pras' AIRFLOW_CTX_DAG_ID='fondue_dag' AIRFLOW_CTX_TASK_ID='clustering' AIRFLOW_CTX_EXECUTION_DATE='2023-05-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-05-12T00:00:00+00:00'
[2023-05-17T18:26:10.815+0000] {logging_mixin.py:149} WARNING - 2023/05/17 18:26:10 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh()

All git commands will error until this is rectified.

This initial warning can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|none|n|0: for no warning or exception
    - warn|w|warning|1: for a printed warning
    - error|e|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet
[2023-05-17T18:26:16.097+0000] {python.py:183} INFO - Done. Returned value was: None
[2023-05-17T18:26:16.115+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=fondue_dag, task_id=clustering, execution_date=20230512T000000, start_date=20230517T182555, end_date=20230517T182616
[2023-05-17T18:26:16.244+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2023-05-17T18:26:16.282+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-05-17T18:37:07.504+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [queued]>
[2023-05-17T18:37:07.525+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [queued]>
[2023-05-17T18:37:07.526+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 2
[2023-05-17T18:37:07.549+0000] {taskinstance.py:1350} INFO - Executing <Task(PythonOperator): clustering> on 2023-05-12 00:00:00+00:00
[2023-05-17T18:37:07.558+0000] {standard_task_runner.py:57} INFO - Started process 760 to run task
[2023-05-17T18:37:07.562+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'fondue_dag', 'clustering', 'scheduled__2023-05-12T00:00:00+00:00', '--job-id', '21', '--raw', '--subdir', 'DAGS_FOLDER/fondue_dag.py', '--cfg-path', '/tmp/tmpw_n4m3_w']
[2023-05-17T18:37:07.566+0000] {standard_task_runner.py:85} INFO - Job 21: Subtask clustering
[2023-05-17T18:37:07.628+0000] {task_command.py:410} INFO - Running <TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [running]> on host 1545bed90dab
[2023-05-17T18:37:07.763+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='Bhuribhat@gmail.com' AIRFLOW_CTX_DAG_OWNER='pras' AIRFLOW_CTX_DAG_ID='fondue_dag' AIRFLOW_CTX_TASK_ID='clustering' AIRFLOW_CTX_EXECUTION_DATE='2023-05-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-05-12T00:00:00+00:00'
[2023-05-17T18:37:10.983+0000] {logging_mixin.py:149} WARNING - 2023/05/17 18:37:10 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh()

All git commands will error until this is rectified.

This initial warning can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|none|n|0: for no warning or exception
    - warn|w|warning|1: for a printed warning
    - error|e|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet
[2023-05-17T18:37:14.945+0000] {python.py:183} INFO - Done. Returned value was: None
[2023-05-17T18:37:14.958+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=fondue_dag, task_id=clustering, execution_date=20230512T000000, start_date=20230517T183707, end_date=20230517T183714
[2023-05-17T18:37:14.990+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2023-05-17T18:37:15.026+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-05-18T06:41:19.587+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [queued]>
[2023-05-18T06:41:19.609+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [queued]>
[2023-05-18T06:41:19.610+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 2
[2023-05-18T06:41:19.645+0000] {taskinstance.py:1350} INFO - Executing <Task(PythonOperator): clustering> on 2023-05-12 00:00:00+00:00
[2023-05-18T06:41:19.657+0000] {standard_task_runner.py:57} INFO - Started process 1382 to run task
[2023-05-18T06:41:19.661+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'fondue_dag', 'clustering', 'scheduled__2023-05-12T00:00:00+00:00', '--job-id', '33', '--raw', '--subdir', 'DAGS_FOLDER/fondue_dag.py', '--cfg-path', '/tmp/tmpa99w9dk5']
[2023-05-18T06:41:19.664+0000] {standard_task_runner.py:85} INFO - Job 33: Subtask clustering
[2023-05-18T06:41:19.758+0000] {task_command.py:410} INFO - Running <TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [running]> on host 714a0c7ad307
[2023-05-18T06:41:19.950+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='Bhuribhat@gmail.com' AIRFLOW_CTX_DAG_OWNER='pras' AIRFLOW_CTX_DAG_ID='fondue_dag' AIRFLOW_CTX_TASK_ID='clustering' AIRFLOW_CTX_EXECUTION_DATE='2023-05-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-05-12T00:00:00+00:00'
[2023-05-18T06:41:45.703+0000] {logging_mixin.py:149} WARNING - 2023/05/18 06:41:45 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh()

All git commands will error until this is rectified.

This initial warning can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|none|n|0: for no warning or exception
    - warn|w|warning|1: for a printed warning
    - error|e|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet
[2023-05-18T06:41:45.897+0000] {logging_mixin.py:149} WARNING - 2023/05/18 06:41:45 INFO mlflow.tracking.fluent: Experiment with name 'fondue' does not exist. Creating a new experiment.
[2023-05-18T06:41:45.901+0000] {taskinstance.py:1847} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 181, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 198, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/utils/clustering.py", line 46, in kmean_cluster
    with mlflow.start_run() as run:
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/tracking/fluent.py", line 277, in start_run
    ).format(_active_run_stack[0].info.run_id)
Exception: Run with UUID 3e26cca5762947ef82b816455dd902bb is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
[2023-05-18T06:41:45.948+0000] {taskinstance.py:1373} INFO - Marking task as UP_FOR_RETRY. dag_id=fondue_dag, task_id=clustering, execution_date=20230512T000000, start_date=20230518T064119, end_date=20230518T064145
[2023-05-18T06:41:46.139+0000] {configuration.py:675} WARNING - section/key [smtp/smtp_user] not found in config
[2023-05-18T06:41:46.141+0000] {email.py:268} INFO - Email alerting: attempt 1
[2023-05-18T06:41:46.151+0000] {configuration.py:675} WARNING - section/key [smtp/smtp_user] not found in config
[2023-05-18T06:41:46.155+0000] {email.py:268} INFO - Email alerting: attempt 1
[2023-05-18T06:41:46.165+0000] {taskinstance.py:1912} ERROR - Failed to send email to: ['Bhuribhat@gmail.com']
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1430, in _run_raw_task
    self._execute_task_with_callbacks(context, test_mode)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1581, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1651, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 181, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 198, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/utils/clustering.py", line 46, in kmean_cluster
    with mlflow.start_run() as run:
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/tracking/fluent.py", line 277, in start_run
    ).format(_active_run_stack[0].info.run_id)
Exception: Run with UUID 3e26cca5762947ef82b816455dd902bb is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2318, in email_alert
    send_email(task.email, subject, html_content)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 91, in send_email
    **kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 152, in send_email_smtp
    send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 270, in send_mime_email
    smtp_conn = _get_smtp_connection(smtp_host, smtp_port, smtp_timeout, smtp_ssl)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 317, in _get_smtp_connection
    else smtplib.SMTP(host=host, port=port, timeout=timeout)
  File "/usr/local/lib/python3.7/smtplib.py", line 251, in __init__
    (code, msg) = self.connect(host, port)
  File "/usr/local/lib/python3.7/smtplib.py", line 336, in connect
    self.sock = self._get_socket(host, port, self.timeout)
  File "/usr/local/lib/python3.7/smtplib.py", line 307, in _get_socket
    self.source_address)
  File "/usr/local/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/usr/local/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 99] Cannot assign requested address

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1910, in handle_failure
    self.email_alert(error, task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2320, in email_alert
    send_email(task.email, subject, html_content_err)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 91, in send_email
    **kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 152, in send_email_smtp
    send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 270, in send_mime_email
    smtp_conn = _get_smtp_connection(smtp_host, smtp_port, smtp_timeout, smtp_ssl)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 317, in _get_smtp_connection
    else smtplib.SMTP(host=host, port=port, timeout=timeout)
  File "/usr/local/lib/python3.7/smtplib.py", line 251, in __init__
    (code, msg) = self.connect(host, port)
  File "/usr/local/lib/python3.7/smtplib.py", line 336, in connect
    self.sock = self._get_socket(host, port, self.timeout)
  File "/usr/local/lib/python3.7/smtplib.py", line 307, in _get_socket
    self.source_address)
  File "/usr/local/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/usr/local/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 99] Cannot assign requested address
[2023-05-18T06:41:46.398+0000] {standard_task_runner.py:109} ERROR - Failed to execute job 33 for task clustering (Run with UUID 3e26cca5762947ef82b816455dd902bb is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True; 1382)
[2023-05-18T06:41:46.440+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 1
[2023-05-18T06:41:46.528+0000] {taskinstance.py:2674} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-18T06:53:41.836+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [queued]>
[2023-05-18T06:53:41.871+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [queued]>
[2023-05-18T06:53:41.895+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 2
[2023-05-18T06:53:41.963+0000] {taskinstance.py:1350} INFO - Executing <Task(PythonOperator): clustering> on 2023-05-12 00:00:00+00:00
[2023-05-18T06:53:41.970+0000] {standard_task_runner.py:57} INFO - Started process 2005 to run task
[2023-05-18T06:53:41.986+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'fondue_dag', 'clustering', 'scheduled__2023-05-12T00:00:00+00:00', '--job-id', '44', '--raw', '--subdir', 'DAGS_FOLDER/fondue_dag.py', '--cfg-path', '/tmp/tmpcghbonyx']
[2023-05-18T06:53:41.993+0000] {standard_task_runner.py:85} INFO - Job 44: Subtask clustering
[2023-05-18T06:53:42.227+0000] {task_command.py:410} INFO - Running <TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [running]> on host 26547302378e
[2023-05-18T06:53:42.447+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='Bhuribhat@gmail.com' AIRFLOW_CTX_DAG_OWNER='pras' AIRFLOW_CTX_DAG_ID='fondue_dag' AIRFLOW_CTX_TASK_ID='clustering' AIRFLOW_CTX_EXECUTION_DATE='2023-05-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-05-12T00:00:00+00:00'
[2023-05-18T06:53:55.612+0000] {logging_mixin.py:149} WARNING - 2023/05/18 06:53:55 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh()

All git commands will error until this is rectified.

This initial warning can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|none|n|0: for no warning or exception
    - warn|w|warning|1: for a printed warning
    - error|e|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet
[2023-05-18T06:54:03.465+0000] {python.py:183} INFO - Done. Returned value was: None
[2023-05-18T06:54:03.488+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=fondue_dag, task_id=clustering, execution_date=20230512T000000, start_date=20230518T065341, end_date=20230518T065403
[2023-05-18T06:54:03.704+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2023-05-18T06:54:03.747+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
=======
[2023-05-18T04:23:16.225+0000] {python.py:183} INFO - Done. Returned value was: None
[2023-05-18T04:23:16.260+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=fondue_dag, task_id=clustering, execution_date=20230512T000000, start_date=20230518T042223, end_date=20230518T042316
[2023-05-18T04:23:16.366+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2023-05-18T04:23:16.406+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
>>>>>>> 8e4a41b368593e9ce283ae02afd6c27252f67370
[2023-05-18T07:21:32.636+0000] {logging_mixin.py:149} INFO - Changing /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering permission to 509
[2023-05-18T07:21:32.638+0000] {logging_mixin.py:149} INFO - Failed to change /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering'
[2023-05-18T07:22:05.506+0000] {logging_mixin.py:149} INFO - Changing /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering permission to 509
[2023-05-18T07:22:05.516+0000] {logging_mixin.py:149} INFO - Failed to change /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering'
[2023-05-18T07:22:06.041+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [queued]>
[2023-05-18T07:22:06.131+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [queued]>
[2023-05-18T07:22:06.133+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 2
[2023-05-18T07:22:06.195+0000] {taskinstance.py:1350} INFO - Executing <Task(PythonOperator): clustering> on 2023-05-12 00:00:00+00:00
[2023-05-18T07:22:06.212+0000] {standard_task_runner.py:57} INFO - Started process 2485 to run task
[2023-05-18T07:22:06.218+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'fondue_dag', 'clustering', 'scheduled__2023-05-12T00:00:00+00:00', '--job-id', '48', '--raw', '--subdir', 'DAGS_FOLDER/fondue_dag.py', '--cfg-path', '/tmp/tmp0v7w1pzx']
[2023-05-18T07:22:06.226+0000] {standard_task_runner.py:85} INFO - Job 48: Subtask clustering
[2023-05-18T07:22:06.376+0000] {logging_mixin.py:149} INFO - Changing /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering permission to 509
[2023-05-18T07:22:06.378+0000] {logging_mixin.py:149} INFO - Failed to change /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering'
[2023-05-18T07:22:06.387+0000] {task_command.py:410} INFO - Running <TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [running]> on host 0a50b96f7e57
[2023-05-18T07:22:06.696+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='Bhuribhat@gmail.com' AIRFLOW_CTX_DAG_OWNER='pras' AIRFLOW_CTX_DAG_ID='fondue_dag' AIRFLOW_CTX_TASK_ID='clustering' AIRFLOW_CTX_EXECUTION_DATE='2023-05-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-05-12T00:00:00+00:00'
[2023-05-18T07:22:11.381+0000] {file_store.py:280} WARNING - Malformed experiment 'models'. Detailed error Yaml file '/opt/***/mlruns/models/meta.yaml' does not exist.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 271, in list_experiments
    experiment = self._get_experiment(exp_id, view_type)
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 405, in _get_experiment
    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 1109, in _read_yaml
    return _read_helper(root, file_name, attempts_remaining=retries)
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 1102, in _read_helper
    result = read_yaml(root, file_name)
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/utils/file_utils.py", line 183, in read_yaml
    raise MissingConfigException("Yaml file '%s' does not exist." % file_path)
mlflow.exceptions.MissingConfigException: Yaml file '/opt/***/mlruns/models/meta.yaml' does not exist.
[2023-05-18T07:22:11.563+0000] {logging_mixin.py:149} WARNING - 2023/05/18 07:22:11 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh()

All git commands will error until this is rectified.

This initial warning can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|none|n|0: for no warning or exception
    - warn|w|warning|1: for a printed warning
    - error|e|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet
[2023-05-18T07:22:23.371+0000] {python.py:183} INFO - Done. Returned value was: None
[2023-05-18T07:22:23.397+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=fondue_dag, task_id=clustering, execution_date=20230512T000000, start_date=20230518T072206, end_date=20230518T072223
[2023-05-18T07:22:23.463+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2023-05-18T07:22:23.515+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-05-18T07:38:38.169+0000] {logging_mixin.py:149} INFO - Changing /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering permission to 509
[2023-05-18T07:38:38.171+0000] {logging_mixin.py:149} INFO - Failed to change /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering'
[2023-05-18T07:38:38.226+0000] {logging_mixin.py:149} INFO - Changing /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering permission to 509
[2023-05-18T07:38:38.228+0000] {logging_mixin.py:149} INFO - Failed to change /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering'
[2023-05-18T07:38:38.266+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [queued]>
[2023-05-18T07:38:38.290+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [queued]>
[2023-05-18T07:38:38.299+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 2
[2023-05-18T07:38:38.356+0000] {taskinstance.py:1350} INFO - Executing <Task(PythonOperator): clustering> on 2023-05-12 00:00:00+00:00
[2023-05-18T07:38:38.372+0000] {standard_task_runner.py:57} INFO - Started process 1317 to run task
[2023-05-18T07:38:38.385+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'fondue_dag', 'clustering', 'scheduled__2023-05-12T00:00:00+00:00', '--job-id', '42', '--raw', '--subdir', 'DAGS_FOLDER/fondue_dag.py', '--cfg-path', '/tmp/tmp3vneaubf']
[2023-05-18T07:38:38.398+0000] {standard_task_runner.py:85} INFO - Job 42: Subtask clustering
[2023-05-18T07:38:38.600+0000] {logging_mixin.py:149} INFO - Changing /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering permission to 509
[2023-05-18T07:38:38.601+0000] {logging_mixin.py:149} INFO - Failed to change /opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=fondue_dag/run_id=scheduled__2023-05-12T00:00:00+00:00/task_id=clustering'
[2023-05-18T07:38:38.604+0000] {task_command.py:410} INFO - Running <TaskInstance: fondue_dag.clustering scheduled__2023-05-12T00:00:00+00:00 [running]> on host 4fe746fadf66
[2023-05-18T07:38:38.818+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='Bhuribhat@gmail.com' AIRFLOW_CTX_DAG_OWNER='pras' AIRFLOW_CTX_DAG_ID='fondue_dag' AIRFLOW_CTX_TASK_ID='clustering' AIRFLOW_CTX_EXECUTION_DATE='2023-05-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-05-12T00:00:00+00:00'
[2023-05-18T07:39:00.863+0000] {file_store.py:280} WARNING - Malformed experiment 'models'. Detailed error Yaml file '/opt/***/mlruns/models/meta.yaml' does not exist.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 271, in list_experiments
    experiment = self._get_experiment(exp_id, view_type)
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 405, in _get_experiment
    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 1109, in _read_yaml
    return _read_helper(root, file_name, attempts_remaining=retries)
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 1102, in _read_helper
    result = read_yaml(root, file_name)
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/utils/file_utils.py", line 183, in read_yaml
    raise MissingConfigException("Yaml file '%s' does not exist." % file_path)
mlflow.exceptions.MissingConfigException: Yaml file '/opt/***/mlruns/models/meta.yaml' does not exist.
[2023-05-18T07:39:01.078+0000] {logging_mixin.py:149} WARNING - 2023/05/18 07:39:01 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh()

All git commands will error until this is rectified.

This initial warning can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|none|n|0: for no warning or exception
    - warn|w|warning|1: for a printed warning
    - error|e|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet
[2023-05-18T07:39:09.585+0000] {python.py:183} INFO - Done. Returned value was: None
[2023-05-18T07:39:09.606+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=fondue_dag, task_id=clustering, execution_date=20230512T000000, start_date=20230518T073838, end_date=20230518T073909
[2023-05-18T07:39:09.652+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2023-05-18T07:39:09.692+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
